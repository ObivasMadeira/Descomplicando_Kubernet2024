O que é um cluster Kubernetes?
Um cluster Kubernetes é um conjunto de nodes que trabalham juntos para executar todos os nossos pods. Um cluster Kubernetes é composto por nodes que podem ser tanto control plane quanto workers. O control plane é responsável por gerenciar o cluster, enquanto os workers são responsáveis por executar os pods que são criados no cluster pelos usuários.
Quando estamos pensando em um cluster Kubernetes, precisamos lembrar que a principal função do Kubernetes é orquestrar containers. O Kubernetes é um orquestrador de containers, sendo assim quando estamos falando de um cluster Kubernetes, estamos falando de um cluster de orquestradores de containers. Eu sempre gosto de pensar em um cluster Kubernetes como se fosse uma orquestra, onde temos uma pessoa regendo a orquestra, que é o control plane, e temos as pessoas musicistas, que estão executando os instrumentos, que são os workers.
Sendo assim, o control plane é responsável por gerenciar o cluster, como por exemplo:
Criar e gerenciar os recursos do cluster, como por exemplo, namespaces, deployments, services, configmaps, secrets, etc.
Gerenciar os workers do cluster.
Gerenciar a rede do cluster.
O etcd desempenha um papel crucial na manutenção da estabilidade e confiabilidade do cluster. Ele armazena as informações de configuração de todos os componentes do control plane, incluindo os detalhes dos serviços, pods e outros recursos do cluster. Graças ao seu design distribuído, o etcd é capaz de tolerar falhas e garantir a continuidade dos dados, mesmo em caso de falha de um ou mais nós. Além disso, ele suporta a comunicação segura entre os componentes do cluster, usando criptografia TLS para proteger os dados.
O scheduler é o componente responsável por decidir em qual nó os pods serão executados, levando em consideração os requisitos e os recursos disponíveis. O scheduler também monitora constantemente a situação do cluster e, se necessário, ajusta a distribuição dos pods para garantir a melhor utilização dos recursos e manter a harmonia entre os componentes.
O controller-manager é responsável por gerenciar os diferentes controladores que regulam o estado do cluster e mantêm tudo funcionando. Ele monitora constantemente o estado atual dos recursos e compara-os com o estado desejado, fazendo ajustes conforme necessário.
Onde está o api-server é o componente central que expõe a API do Kubernetes, permitindo que outros componentes do control plane, como o controller-manager e o scheduler, bem como ferramentas externas, se comuniquem e interajam com o cluster. O api-server é a principal interface de comunicação do Kubernetes, autenticando e autorizando solicitações, processando-as e fornecendo as respostas apropriadas. Ele garante que as informações sejam compartilhadas e acessadas de forma segura e eficiente, possibilitando uma colaboração harmoniosa entre todos os componentes do cluster.
Já no lado dos workers, as coisa são bem mais simples, pois a principal função deles é executar os pods que são criados no cluster pelos usuários. Nos workers nós temos, por padrão, os seguintes componentes do Kubernetes:
O kubelet é o agente que funciona em cada nó do cluster, garantindo que os containers estejam funcionando conforme o esperado dentro dos pods. Ele assume o controle de cada nó, garantindo que os containers estejam sendo executados conforme as instruções recebidas do control plane. Ele monitora constantemente o estado atual dos pods e compara-os com o estado desejado. Caso haja alguma divergência, o kubelet faz os ajustes necessários para que os containers sigam funcionando perfeitamente.
O kube-proxy, que é o componente responsável fazer ser possível que os pods e os services se comuniquem entre si e com o mundo externo. Ele observa o control plane para identificar mudanças na configuração dos serviços e, em seguida, atualiza as regras de encaminhamento de tráfego para garantir que tudo continue fluindo conforme o esperado.
Todos os pods de nossas aplicações.
================================================

Formas de instalar o Kubernetes
Hoje nós iremos focar a instalação do Kubernetes utilizando o kubeadm, que é uma das formas mais antigas para a criação de um cluster Kubernetes. Mas existem outras formas de instalar o Kubernetes, vou detalhar algumas delas aqui:
kubeadm: É uma ferramenta para criar e gerenciar um cluster Kubernetes em vários nós. Ele automatiza muitas das tarefas de configuração do cluster, incluindo a instalação do control plane e dos nodes. É altamente configurável e pode ser usado para criar clusters personalizados.
Kubespray: É uma ferramenta que usa o Ansible para implantar e gerenciar um cluster Kubernetes em vários nós. Ele oferece muitas opções para personalizar a instalação do cluster, incluindo a escolha do provedor de rede, o número de réplicas do control plane, o tipo de armazenamento e muito mais. É uma boa opção para implantar um cluster em vários ambientes, incluindo nuvens públicas e privadas.
Cloud Providers: Muitos provedores de nuvem, como AWS, Google Cloud Platform e Microsoft Azure, oferecem opções para implantar um cluster Kubernetes em sua infraestrutura. Eles geralmente fornecem modelos predefinidos que podem ser usados para implantar um cluster com apenas alguns cliques. Alguns provedores de nuvem também oferecem serviços gerenciados de Kubernetes que lidam com toda a configuração e gerenciamento do cluster.
Kubernetes Gerenciados: São serviços gerenciados oferecidos por alguns provedores de nuvem, como Amazon EKS, o GKE do Google Cloud e o AKS, da Azure. Eles oferecem um cluster Kubernetes gerenciado onde você só precisa se preocupar em implantar e gerenciar seus aplicativos. Esses serviços lidam com a configuração, atualização e manutenção do cluster para você. Nesse caso, você não tem que gerenciar o control plane do cluster, pois ele é gerenciado pelo provedor de nuvem.
Kops: É uma ferramenta para implantar e gerenciar clusters Kubernetes na nuvem. Ele foi projetado especificamente para implantação em nuvens públicas como AWS, GCP e Azure. Kops permite criar, atualizar e gerenciar clusters Kubernetes na nuvem. Algumas das principais vantagens do uso do Kops são a personalização, escalabilidade e segurança. No entanto, o uso do Kops pode ser mais complexo do que outras opções de instalação do Kubernetes, especialmente se você não estiver familiarizado com a nuvem em que está implantando.
Minikube e kind: São ferramentas que permitem criar um cluster Kubernetes localmente, em um único nó. São úteis para testar e aprender sobre o Kubernetes, pois você pode criar um cluster em poucos minutos e começar a implantar aplicativos imediatamente. Elas também são úteis para pessoas desenvolvedoras que precisam testar suas aplicações em um ambiente Kubernetes sem precisar configurar um cluster em um ambiente de produção.
Ainda existem outras formas de instalar o Kubernetes, mas essas são as mais comuns. Para mais detalhes sobre as outras formas de instalar o Kubernetes, você pode consultar a documentação oficial do Kubernetes.

Portas necessárias

Porta 6443: É a porta padrão usada pelo Kubernetes API Server para se comunicar com os componentes do cluster. É a porta principal usada para gerenciar o cluster e deve estar sempre aberta.
Portas 10250-10255: Essas portas são usadas pelo kubelet para se comunicar com o control plane do Kubernetes. A porta 10250 é usada para comunicação de leitura/gravação e a porta 10255 é usada apenas para comunicação de leitura.
Porta 30000-32767: Essas portas são usadas para serviços NodePort que precisam ser acessíveis fora do cluster. O Kubernetes aloca uma porta aleatória dentro desse intervalo para cada serviço NodePort e redireciona o tráfego para o pod correspondente.
Porta 2379-2380: Essas portas são usadas pelo etcd, o banco de dados de chave-valor distribuído usado pelo control plane do Kubernetes. A porta 2379 é usada para comunicação de leitura/gravação e a porta 2380 é usada apenas para comunicação de eleição.

========================================

Iniciamos 3 instâncias ec2 na aws.
Agora vamos preparar as mesmas

 Desativar o swap
sudo swapoff -a

 Criar o arquivo k8s.conf
sudo vim /etc/modules-load.d/k8s.conf
overlay
br_netfilter



sudo modprobe overlay
sudo modprobe br_netfilter

Vamos criar mais um k8s.conf
sudo vim /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1

 Vamos atualizar as máquinas
sudo apt-get update

Instalando pacotes adicionais e o Kubernetes versão 1.28.1:

sudo apt-get update
sudo apt-get install apt-transport-https ca-certificates curl -y

# Carregar a chave para instalação dos pacotes do k8s
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Adicionar o pacote do Kubernetes no arquivo "kubernetes.list"
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Atualizar
sudo apt-get update

# Instalar os pacotes
sudo apt install -y kubeadm=1.28.1-1.1 kubelet=1.28.1-1.1 kubectl=1.28.1-1.1

# Adicionar os pacotes para não atualizar automaticamente, evitar quebrar o cluster
sudo apt-mark hold kubelet kubeadm kubectl

========================================================

Instalando container runtime - containerd
sudo apt-get update && sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release

# Copiar a chave do repositório do docker para acessar o repositório assinado
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Baixar o conteúdo
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

#Instalar containerd
sudo apt-get update && sudo apt-get install -y containerd.io

Configurar o containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml

#Alterando a configuração do SystemdCgroup para 'true'
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

sudo systemctl restart containerd
sudo systemctl status containerd
sudo systemctl enable containerd

Habilitar o kubelet

# Início automático com o sistema
sudo systemctl enable --now kubelet

Inicializar a partir do nodo 1 do controlplane:

# Init para iniciar, passar rede que vai ser usada e a interface de rede que o kubeadm vai usar para comunicar com demais nós
sudo kubeadm init --pod-network-cidr=10.10.0.0/16 --apiserver-advertise-address=<O IP QUE VAI FALAR COM OS NODES>
==========================================
Depois de fazer todas as configurações e parametrizações necessárias vamos de fato iniciar nosso cluster k8s.
Agora vamos escolher umas das instâncias ec2 para ser o control plane, nosso caso escohemos a máquina k8s-01.

Inicializar a partir do nodo 1 do controlplane:

# Init para iniciar, passar rede que vai ser usada e a interface de rede que o kubeadm vai usar para comunicar com demais nós
sudo kubeadm init --pod-network-cidr=10.10.0.0/16 --apiserver-advertise-address=<O IP QUE VAI FALAR COM OS NODES IP da sua máquina atual>


Após execução o próprio retorno do comando irá mostrar novos comando a serem executados,
que são basicamente: Como acessar o cluster com usuário regular ou root,
como fazer um deploy de um POD e como fazer o deploy de um nodo worker, usando um usuário root:


Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.57.89:6443 --token if9hn9.xhxo6s89byj9rsmd \
	--discovery-token-ca-cert-hash sha256:ad583497a4171d1fc7d21e2ca2ea7b32bdc8450a1a4ca4cfa2022748a99fa477 

=========================================

Essa configuração é necessária para que o kubectl possa se comunicar com o cluster, pois quando estamos copiando o arquivo admin.conf para o diretório .kube do usuário, estamos copiando o arquivo com as permissões de root, esse é o motivo de executarmos o comando sudo chown $(id -u):$(id -g) $HOME/.kube/config para alterar as permissões do arquivo para o usuário que está executando o comando.

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
export KUBECONFIG=$HOME/.kube/config/config

Entendendo o arquivo admin.conf
É um arquivo de configuração do kubectl, que é o cliente de linha de comando do Kubernetes. Ele é usado para se comunicar com o cluster Kubernetes.
apiVersion: v1

#A seção clusters contém informações sobre os clusters Kubernetes que você deseja acessar, como o endereço do servidor API e o certificado de autoridade. Neste arquivo, há somente um cluster chamado kubernetes, que é o cluster que acabamos de criar.
clusters:
- cluster:
    certificate-authority-data: SEU_CERTIFICADO_AQUI
    server: https://172.31.57.89:6443
  name: kubernetes

#seção contexts define configurações específicas para cada combinação de cluster, usuário e namespace. Pode ter mais de um contexto dentro do `admin.conf`, por exemplo, um para o cluster de produção outro para homologação. Nesse caso, ele é chamado kubernetes-admin@kubernetes e combina o cluster kubernetes com o usuário kubernetes-admin.
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes

#A propriedade current-context indica o contexto atualmente ativo, ou seja, qual combinação de cluster, usuário e namespace será usada ao executar comandos kubectl. Neste arquivo, o contexto atual é o kubernetes-admin@kubernetes.
current-context: kubernetes-admin@kubernetes

kind: Config

#A seção preferences contém configurações globais que afetam o comportamento do kubectl. Aqui podemos definir o editor de texto padrão, por exemplo.
preferences: {}

#A seção users contém informações sobre os usuários e suas credenciais para acessar os clusters. Neste arquivo, há somente um usuário chamado kubernetes-admin. Ele contém os dados do certificado de cliente e da chave do cliente.
users:
- name: kubernetes-admin
  user:
    client-certificate-data: SUA_CHAVE_PUBLICA_AQUI
    client-key-data: SUA_CHAVE_PRIVADA_AQUI
Credenciais usadas para autenticar o usuário:

Token de autenticação:Token de acesso que é usado para autenticar o usuário que está executando o comando kubectl. Gerado automaticamente quando o cluster é inicializado.

certificate-authority-data: Certificado em base64 da autoridade de certificação (CA) do cluster. Responsável por assinar e emitir certificados para o cluster. Usado para verificar a autenticidade dos certificados apresentados pelo servidor de API e pelos clientes, garantindo que a comunicação entre eles seja segura e confiável. Pode ser encontrado em: /etc/kubernetes/pki/ca.crt.

client-certificate-data: Certificado do cliente. Usado para autenticar o usuário ao se comunicar com o servidor de API do Kubernetes. Contém informações do usuário e a chave pública. Pode ser encontrado em: /etc/kubernetes/pki/apiserver-kubelet-client.crt.

client-key-data: Chave privada do cliente. A chave privada é usada para assinar as solicitações enviadas ao servidor de API do Kubernetes, permitindo que o servidor verifique a autenticidade da solicitação. Pode ser encontrado em: /etc/kubernetes/pki/apiserver-kubelet-client.key.

Outra forma de acessar o admin.conf:

kubectl config view
Adicionar 2 workers no cluster
Executar o comando que retornou na inicialização do cluster, com o kubeadm.

Executar em cada nodo:

sudo kubeadm join 172.31.57.89:6443 --token if9hn9.xhxo6s89byj9rsmd \
	--discovery-token-ca-cert-hash sha256:ad583497a4171d1fc7d21e2ca2ea7b32bdc8450a1a4ca4cfa2022748a99fa477 
kubeadm join: Adicionar um novo nó ao cluster. 172.31.57.89:6443: Endereço IP e porta do servidor de API do control plane
--token if9hn9.xhxo6s89byj9rsmd: O token para o worker no CP durante o processo de adesão. Dão gerados pelo CP e têm uma validade limitada (por padrão, 24 horas).
--discovery-token-ca-cert-hash sha256:ad583497a4171d1fc7d21e2ca2ea7b32bdc8450a1a4ca4cfa2022748a99fa477: Hash criptografado do CA do control plane. Ele é usado para garantir que o nó worker esteja se comunicando com o control plane correto e autêntico.
Ver novos nodos. Perceber se estão com status Ready:

kubectl get nodes
Instalando o Weave Net
Instalar o plugin de rede que vai criar a rede de comunicação entre os pods. Por padrão, o k8s não resolve a rede automaticamente, por isso precisa ser instalado um plugin adicional.

CNI - conjunto de bibliotecas e especificações para interface de rede em containers, para criar plugins para soluções de rede integradas com k8s.

Exemplos de plugins de mercado:

Calico um dos mais populares e utilizado no k8s. https://github.com/projectcalico/calico

Flannel simples e fácil de configurar, projetado para o Kubernetes. https://github.com/flannel-io/flannel

Weave é outra solução popular de rede para Kubernetes.https://github.com/weaveworks/weave

Cilium é um plugin de rede novo focado em segurança e desempenho. oferece recursos avançados, como balanceamento de carga, monitoramento e solução de problemas de rede. https://cilium.io/

Kube-router é uma solução de rede leve para Kubernetes.

Nesse caso vamos testar com Weave Net. Executar somente no Control Plane:

kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
Não esquecer de liberar as portas do Weave Net, nesse caso temos que fazer a liberação na AWS.

  Portas: 6783 TCP e 6784 UDP

  Se não houver a liberação os pods não irão subir.

Verificar a os pods do Weave Net após a instalação:

kubectl get pods -n kube-system
Para verificar se os pods de aplicações estão sendo criados corretamente após a instalação do cluster e plugin de rede, pode instalar uma API e validar:

kubectl create deployment nginx --image=nginx --replicas=3
kubectl get pods -o wide
Ver detalhes dos nodos criados:

kubectl get nodes -o wide
kubectl describe nodes k8s-controlplane
---------------------------------------------------

Comando importante para crear novo token e novo token-ca

Você pode gerar um novo token se necessário:
sudo kubeadm token create

E então obtenha o discovery-token-ca-cert-hash novamente:
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | \
    openssl rsa -pubin -outform der 2>/dev/null | \
    openssl dgst -sha256 -hex | sed 's/^.* //'
