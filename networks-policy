O que iremos ver hoje?

Hoje vamos dedicar o nosso tempo para entender o mundo das Network Policies no Kubernetes. Essa é uma ferramenta essencial para a segurança e o gerenciamento eficaz da comunicação entre os Pods em um cluster Kubernetes. Vamos aprender como as Network Policies funcionam, suas aplicações práticas e como você pode implementá-las para proteger suas aplicações no Kubernetes.
Com certeza será um dia com muito conteúdo e aprendizado. Bora lá?
O que são Network Policies?

No Kubernetes, uma Network Policy é um conjunto de regras que definem como os Pods podem se comunicar entre si e com outros endpoints de rede. Por padrão, os Pods em um cluster Kubernetes podem se comunicar livremente entre si, o que pode não ser ideal para todos os cenários. As Network Policies permitem que você restrinja esse acesso, garantindo que apenas o tráfego permitido possa fluir entre os Pods ou para/endereços IP externos.
Para que Servem as Network Policies?

Network Policies são usadas para:

    Isolar Pods de tráfego não autorizado.
    Controlar o acesso à serviços específicos.
    Implementar padrões de segurança e conformidade.

Conceitos Fundamentais: Ingress e Egress

    Ingress: Regras de ingresso controlam o tráfego de entrada para um Pod.
    Egress: Regras de saída controlam o tráfego de saída de um Pod.

Ter o entendimento desses conceitos é fundamental para entender como as Network Policies funcionam, pois você precisará especificar se uma regra se aplica ao tráfego de entrada ou de saída.
Como Funcionam as Network Policies?

Network Policies utilizam SELECTORS para identificar grupos de Pods e definir regras de tráfego para eles. A política pode especificar:

    Ingress (entrada): quais Pods ou endereços IP podem se conectar a Pods selecionados.
    Egress (saída): para quais Pods ou endereços IP os Pods selecionados podem se conectar.

Ainda não é padrão

Infelizmente, as Network Policies ainda não são um recurso padrão em todos os clusters Kubernetes. 

Recentemente a AWS anunciou o suporte a Network Policies no EKS, mas ainda não é um recurso padrão, para que você possa utilizar as Network Policies no EKS, você precisa instalar o CNI da AWS e depois habilitar o Network Policy nas configurações avançadas do CNI.

Para verificar se o seu cluster suporta Network Policies, você pode executar o seguinte comando:

kubectl api-versions | grep networking

Se você receber a mensagem networking.k8s.io/v1, significa que o seu cluster suporta Network Policies. Se você receber a mensagem networking.k8s.io/v1beta1, significa que o seu cluster não suporta Network Policies.

Se o seu cluster não suportar Network Policies, você pode utilizar o Calico para implementar as Network Policies no seu cluster. Para isso, você precisa instalar o Calico no seu cluster. Você pode encontrar mais informações sobre o Calico aqui.

Outros CNI que suportam Network Policies são o Weave Net e o Cilium, por exemplo.

=======================================================

Para o funcionamento correto do networkpolicy no kind, tivemos q criar um cluster novo com a seguinte configuração:

Calico no KIND: É uma prática comum desativar o CNI padrão do KIND para instalar o Calico, que é o padrão da indústria para testar políticas de rede complexas.

kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4

networking:
  disableDefaultCNI: true  # Desativa o kindnetd (você vai instalar outro CNI, ex: Calico/Cilium)

nodes:
  - role: control-plane

  - role: worker
  - role: worker
  - role: worker

=========================================

Agora vamos instar o nginx-controller para o nosso teste ficar show
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.5/deploy/static/provider/cloud/deploy.yaml
namespace/ingress-nginx created
serviceaccount/ingress-nginx created
serviceaccount/ingress-nginx-admission created
role.rbac.authorization.k8s.io/ingress-nginx created
role.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrole.rbac.authorization.k8s.io/ingress-nginx created
clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created
rolebinding.rbac.authorization.k8s.io/ingress-nginx created
rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
configmap/ingress-nginx-controller created
service/ingress-nginx-controller created
service/ingress-nginx-controller-admission created
deployment.apps/ingress-nginx-controller created
job.batch/ingress-nginx-admission-create created
job.batch/ingress-nginx-admission-patch created
ingressclass.networking.k8s.io/nginx created
validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created

================================================
Vamos criar a primeiro netpol para limitar o acesso de outros pod fora da nossa namespace giropops

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-deny-from-outside
  namespace: giropops
spec:
  podSelector:
    matchLabels:
      app: redis
  ingress:
  - from:
    - podSelector: {}

Para testar rodamos um

k run -ti alpine --image alpine --sh

e dentro deles

instalamos primeiro o curl para teste, "apk add curl"

curl girpops-senhas.giropos.svc.cluster.local:500
isso ira trazer o html do giropos-senhas

tb podemos testar o redis
 apk add redis

redis-cli -h redis-service.svc ping o redis ira responder "pong"

Mas depois de subir essa netpol, ao tentar fazer o mesmo passo a passo de curl essa netpol não ira permitir somente se o pod do curl estiver na namespace giropops

